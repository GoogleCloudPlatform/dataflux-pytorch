{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "First, we install the Dataflux Dataset for PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install gcs-torch-dataflux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we need to install the rest of the rest of the expected packages for this demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install torch\n",
    "! pip install lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "\n",
    "After installing all required packages, we must perform some additional preparation.\n",
    "\n",
    "First, we set up the [authentication](https://github.com/GoogleCloudPlatform/dataflux-pytorch?tab=readme-ov-file#configuration) needed to run the notebook.\n",
    "\n",
    "Modify the `PROJECT_ID` field to your own project ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import auth\n",
    "PROJECT_ID = \"YOUR_PROJECT_ID\"\n",
    "auth.authenticate_user(project_id=PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lightning Checkpointing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Dataflux PyTorch offers an optional implementation of PyTorch Lightning's checkpoints through implmentation of the CheckpointIO interface.\n",
    "\n",
    "The methods that are supported are `save_checkpoint`, `load_checkpoint`, `remove_checkpoint` and `teardown`. \n",
    "\n",
    "First construct a DatafluxLightningCheckpoint.\n",
    "\n",
    "Modify the `BUCKET_NAME` field to your own bucket name within the your project and `CKPT_PATH` field to the path you would like to test with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataflux_pytorch.lightning import DatafluxLightningCheckpoint\n",
    "\n",
    "BUCKET_NAME=\"YOUR_BUCKET_NAME\"\n",
    "dataflux_ckpt = DatafluxLightningCheckpoint(project_name=PROJECT_ID, bucket_name=BUCKET_NAME)\n",
    "CKPT_PATH = \"gcs://YOUR_BUCKET_NAME/demo/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure your datset, dataloader and model have been defined. This example pulls from the PyTorch demos datasets for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.demos import WikiText2, LightningTransformer\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataset = WikiText2()\n",
    "dataloader = DataLoader(dataset, num_workers=1)\n",
    "\n",
    "model = LightningTransformer(vocab_size=dataset.vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lightning contains automatic checkpoint support through the use of callbacks. Using a `ModelCheckpoint` you can determine the settings around your checkpointing. For example, the `filename` sets the naming convention for your checkpoint files and `every_n_train_steps` sets the checkpointing frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    save_top_k=-1,\n",
    "    every_n_train_steps=1,\n",
    "    filename=\"checkpoint-{epoch:02d}-{step:02d}\",\n",
    "    enable_version_counter=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `trainer.fit()` will run the model and using the callbacks our checkpoints will be saved every step. Check the `CKPT_PATH` to see your checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning import Trainer\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "\n",
    "trainer = Trainer(\n",
    "    default_root_dir=CKPT_PATH,\n",
    "    callbacks=[checkpoint_callback],\n",
    "    plugins=[dataflux_ckpt],\n",
    "    min_epochs=4,\n",
    "    max_epochs=5,\n",
    "    max_steps=3,\n",
    "    accelerator=\"cpu\",\n",
    ")\n",
    "trainer.fit(model, dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the trainer you can now save, load and remove the checkpoint manually as well.\n",
    "\n",
    "For example you would save the checkpoint to the `CKPT_PATH` by calling `save_checkpoint`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_checkpoint(CKPT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can verify the method by checking your bucket to see the checkpoint saved to `CKPT_PATH`."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
