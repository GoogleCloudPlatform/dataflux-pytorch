#  Copyright 2024 Google LLC

#  Licensed under the Apache License, Version 2.0 (the "License");
#  you may not use this file except in compliance with the License.
#  You may obtain a copy of the License at

#       https://www.apache.org/licenses/LICENSE-2.0

#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an "AS IS" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.

apiVersion: jobset.x-k8s.io/v1alpha2
kind: JobSet
metadata:
  name: dataflux-pytorch-l-multi-node-4-nodes
  labels:
    kueue.x-k8s.io/queue-name: multislice-queue  # Name of the LocalQueue
  annotations:
    alpha.jobset.sigs.k8s.io/exclusive-topology: cloud.google.com/gke-nodepool # 1:1 job replica to node pool assignment
spec:
  failurePolicy:
    maxRestarts: 0
  replicatedJobs:
    - name: slice-job
      replicas: 1
      template:
        spec:
          parallelism: 4    # Equal to the number of VMs per slice
          completions: 4    # Same as the above.
          backoffLimit: 0   # When any pod fails, the job is failed
          template:
            spec:
              schedulerName: default-scheduler
              restartPolicy: Never
                
              priorityClassName: medium
              hostNetwork: true
              dnsPolicy: ClusterFirstWithHostNet
              terminationGracePeriodSeconds: 30
              containers:
              - name: workload-cpu
                image: <YOUR-CONTAINER-IMAGE>
                env: 
                - name: REPLICATED_JOB_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.annotations['jobset.sigs.k8s.io/replicatedjob-name']
                - name: JOB_INDEX
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.annotations['jobset.sigs.k8s.io/job-index']
                - name: JOB_COMPLETION_INDEX
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.annotations['batch.kubernetes.io/job-completion-index']
                - name: PROCESSES_IN_JOB
                  value: "2"
                # WORLD_SIZE must match with num_nodes argument passed to train.py.
                - name: WORLD_SIZE
                  value: "4"
                - name: JOBSET_NAME
                  value: "dataflux-pytorch-l-multi-node-4-nodes"
                - name: COORDINATOR_ADDRESS
                  value: "$(JOBSET_NAME)-$(REPLICATED_JOB_NAME)-0-0.$(JOBSET_NAME)"
                - name: MASTER_PORT
                  value: "1234"
  
                ports:
                - containerPort: 8471
                - containerPort: 8080
                - containerPort: 1234
                securityContext: {}
                  # privileged: true
                volumeMounts:
                 - mountPath: /dev/shm
                   name: dshm
                command:
                - bash
                - -c
                - |
                  python3 -u /app/demo/lightning/image-segmentation/train.py --gcp_project=<YOUR-GCP-PROJECT> --images_prefix=<YOUR-IMAGES-PREFIX> --labels_prefix=<YOUR-LABELS-PREFIX> --gcs_bucket=<YOUR-GCS-BUCKET> --num_workers=10 --prefetch_factor=10 --num_devices=1 --num_nodes=4;
              volumes:
                - emptyDir:
                    medium: Memory
                    # Shared memory size; update as needed.
                    sizeLimit: 100Gi
                  name: dshm